{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11 - Deep Network on CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import ssl\n",
    "import matplotlib.pyplot as plt \n",
    "from functools import partial \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = X_train_full[:40000], y_train_full[:40000], X_train_full[40000:], y_train_full[40000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default DNN Architecture \n",
    "- LeCun Initialiation\n",
    "- ELU Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "DenseLayer = partial(\n",
    "    keras.layers.Dense, \n",
    "    activation = 'elu',\n",
    "    kernel_initializer = 'he_normal'\n",
    ")\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(DenseLayer(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 3072)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               307300    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('models/ch11_model.h5', save_best_only=True)\n",
    "run_index = 1\n",
    "run_logdir = os.path.join(os.curdir, 'cifar10_logs', 'run_{:03d}'.format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default learning rate works alright, but not as good as 5e-5\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.Nadam(learning_rate=5e-5),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 18s 12ms/step - loss: 4.7200 - accuracy: 0.1420 - val_loss: 2.2326 - val_accuracy: 0.1847\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 2.1254 - accuracy: 0.2159 - val_loss: 2.0535 - val_accuracy: 0.2408\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.9986 - accuracy: 0.2634 - val_loss: 1.9302 - val_accuracy: 0.2881\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.9035 - accuracy: 0.3004 - val_loss: 1.8619 - val_accuracy: 0.3117\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.8382 - accuracy: 0.3273 - val_loss: 1.8116 - val_accuracy: 0.3422\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.7964 - accuracy: 0.3431 - val_loss: 1.8478 - val_accuracy: 0.3218\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.7539 - accuracy: 0.3616 - val_loss: 1.7696 - val_accuracy: 0.3538\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.7253 - accuracy: 0.3743 - val_loss: 1.7767 - val_accuracy: 0.3600\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.6888 - accuracy: 0.3842 - val_loss: 1.7090 - val_accuracy: 0.3810\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 1.6660 - accuracy: 0.3964 - val_loss: 1.6943 - val_accuracy: 0.3867\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.6428 - accuracy: 0.4044 - val_loss: 1.6746 - val_accuracy: 0.4054\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.6193 - accuracy: 0.4131 - val_loss: 1.6636 - val_accuracy: 0.4011\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.6012 - accuracy: 0.4199 - val_loss: 1.6632 - val_accuracy: 0.3992\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.5755 - accuracy: 0.4287 - val_loss: 1.6444 - val_accuracy: 0.4101\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.5584 - accuracy: 0.4363 - val_loss: 1.6392 - val_accuracy: 0.4156\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.5426 - accuracy: 0.4429 - val_loss: 1.6461 - val_accuracy: 0.4099\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.5260 - accuracy: 0.4488 - val_loss: 1.6200 - val_accuracy: 0.4213\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.5073 - accuracy: 0.4555 - val_loss: 1.6239 - val_accuracy: 0.4189\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.4993 - accuracy: 0.4579 - val_loss: 1.6022 - val_accuracy: 0.4275\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.4837 - accuracy: 0.4647 - val_loss: 1.6069 - val_accuracy: 0.4203\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.4727 - accuracy: 0.4650 - val_loss: 1.6355 - val_accuracy: 0.4102\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.4559 - accuracy: 0.4752 - val_loss: 1.5798 - val_accuracy: 0.4385\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.4442 - accuracy: 0.4770 - val_loss: 1.5938 - val_accuracy: 0.4362\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.4333 - accuracy: 0.4799 - val_loss: 1.5896 - val_accuracy: 0.4382\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.4201 - accuracy: 0.4868 - val_loss: 1.5684 - val_accuracy: 0.4469\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.4092 - accuracy: 0.4922 - val_loss: 1.5687 - val_accuracy: 0.4441\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.3975 - accuracy: 0.4943 - val_loss: 1.5771 - val_accuracy: 0.4460\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.3849 - accuracy: 0.5008 - val_loss: 1.5917 - val_accuracy: 0.4387\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.3771 - accuracy: 0.5039 - val_loss: 1.5637 - val_accuracy: 0.4509\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.3663 - accuracy: 0.5067 - val_loss: 1.5682 - val_accuracy: 0.4465\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.3537 - accuracy: 0.5121 - val_loss: 1.5648 - val_accuracy: 0.4507\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.3425 - accuracy: 0.5148 - val_loss: 1.5674 - val_accuracy: 0.4514\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.3370 - accuracy: 0.5191 - val_loss: 1.5571 - val_accuracy: 0.4546\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.3230 - accuracy: 0.5215 - val_loss: 1.5574 - val_accuracy: 0.4513\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.3143 - accuracy: 0.5264 - val_loss: 1.5708 - val_accuracy: 0.4458\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.3035 - accuracy: 0.5329 - val_loss: 1.5787 - val_accuracy: 0.4508\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.2947 - accuracy: 0.5352 - val_loss: 1.5614 - val_accuracy: 0.4577\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.2878 - accuracy: 0.5372 - val_loss: 1.5798 - val_accuracy: 0.4501\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.2790 - accuracy: 0.5378 - val_loss: 1.5672 - val_accuracy: 0.4585\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.2669 - accuracy: 0.5437 - val_loss: 1.5878 - val_accuracy: 0.4526\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.2621 - accuracy: 0.5445 - val_loss: 1.5870 - val_accuracy: 0.4582\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.2505 - accuracy: 0.5491 - val_loss: 1.6052 - val_accuracy: 0.4483\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.2414 - accuracy: 0.5508 - val_loss: 1.5933 - val_accuracy: 0.4551\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.2324 - accuracy: 0.5544 - val_loss: 1.6106 - val_accuracy: 0.4506\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.2268 - accuracy: 0.5563 - val_loss: 1.6215 - val_accuracy: 0.4532\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.2178 - accuracy: 0.5608 - val_loss: 1.6059 - val_accuracy: 0.4589\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.2097 - accuracy: 0.5631 - val_loss: 1.6114 - val_accuracy: 0.4544\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.1995 - accuracy: 0.5674 - val_loss: 1.5953 - val_accuracy: 0.4583\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.1967 - accuracy: 0.5688 - val_loss: 1.6165 - val_accuracy: 0.4517\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.1844 - accuracy: 0.5730 - val_loss: 1.6207 - val_accuracy: 0.4561\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.1786 - accuracy: 0.5734 - val_loss: 1.6139 - val_accuracy: 0.4562\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.1641 - accuracy: 0.5814 - val_loss: 1.6392 - val_accuracy: 0.4534\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 1.1607 - accuracy: 0.5834 - val_loss: 1.6305 - val_accuracy: 0.4547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2473926f130>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5956 - accuracy: 0.4578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5956181287765503, 0.4578000009059906]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Batch Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer='he_normal'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('elu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 3072)              0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 3072)             12288     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               307300    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 520,498\n",
      "Trainable params: 510,354\n",
      "Non-trainable params: 10,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback method to decrease lr exponentially after 10 epochs\n",
    "# NOT FOR FINDING OPTIMAL RATE, METHOD OF TRAINING THAT DECREASES LR AS CONVERGENCE BEGINS\n",
    "def exp_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(exp_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('models/ch11_model_batchnorm.h5', save_best_only=True)\n",
    "run_logdir = os.path.join(os.curdir, 'cifar10_logs_batchnorm', 'run_{:03d}'.format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 35s 20ms/step - loss: 1.8483 - accuracy: 0.3365 - val_loss: 1.6725 - val_accuracy: 0.3963\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.6730 - accuracy: 0.4025 - val_loss: 1.6088 - val_accuracy: 0.4309\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 1.6026 - accuracy: 0.4291 - val_loss: 1.5504 - val_accuracy: 0.4446\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.5550 - accuracy: 0.4439 - val_loss: 1.4790 - val_accuracy: 0.4730\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 1.5083 - accuracy: 0.4619 - val_loss: 1.4633 - val_accuracy: 0.4716\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 1.4756 - accuracy: 0.4762 - val_loss: 1.4465 - val_accuracy: 0.4893\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 1.4425 - accuracy: 0.4877 - val_loss: 1.4169 - val_accuracy: 0.4946\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 1.4117 - accuracy: 0.4963 - val_loss: 1.3953 - val_accuracy: 0.5023\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 1.3869 - accuracy: 0.5058 - val_loss: 1.3973 - val_accuracy: 0.5065\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.3642 - accuracy: 0.5155 - val_loss: 1.4005 - val_accuracy: 0.5003\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 1.3376 - accuracy: 0.5264 - val_loss: 1.3763 - val_accuracy: 0.5180\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.3209 - accuracy: 0.5311 - val_loss: 1.3737 - val_accuracy: 0.5172\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.2981 - accuracy: 0.5401 - val_loss: 1.3832 - val_accuracy: 0.5160\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 1.2838 - accuracy: 0.5462 - val_loss: 1.3788 - val_accuracy: 0.5113\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.2642 - accuracy: 0.5524 - val_loss: 1.3883 - val_accuracy: 0.5101\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.2432 - accuracy: 0.5595 - val_loss: 1.3668 - val_accuracy: 0.5186\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.2287 - accuracy: 0.5642 - val_loss: 1.3602 - val_accuracy: 0.5221\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.2184 - accuracy: 0.5686 - val_loss: 1.3659 - val_accuracy: 0.5215\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.2014 - accuracy: 0.5738 - val_loss: 1.3745 - val_accuracy: 0.5225\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 1.1867 - accuracy: 0.5799 - val_loss: 1.3683 - val_accuracy: 0.5290\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 1.1683 - accuracy: 0.5877 - val_loss: 1.3877 - val_accuracy: 0.5182\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 1.1539 - accuracy: 0.5944 - val_loss: 1.3585 - val_accuracy: 0.5323\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 1.1420 - accuracy: 0.6000 - val_loss: 1.3717 - val_accuracy: 0.5316\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 1.1246 - accuracy: 0.6016 - val_loss: 1.3529 - val_accuracy: 0.5365\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 1.1227 - accuracy: 0.6017 - val_loss: 1.3689 - val_accuracy: 0.5278\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 1.1087 - accuracy: 0.6086 - val_loss: 1.3783 - val_accuracy: 0.5255\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 1.0894 - accuracy: 0.6149 - val_loss: 1.3765 - val_accuracy: 0.5249\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 1.0788 - accuracy: 0.6190 - val_loss: 1.3582 - val_accuracy: 0.5339\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 1.0717 - accuracy: 0.6206 - val_loss: 1.3936 - val_accuracy: 0.5283\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 1.0584 - accuracy: 0.6270 - val_loss: 1.3705 - val_accuracy: 0.5364\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 1.0519 - accuracy: 0.6274 - val_loss: 1.3829 - val_accuracy: 0.5300\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 1.0355 - accuracy: 0.6328 - val_loss: 1.3775 - val_accuracy: 0.5361\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 1.0232 - accuracy: 0.6426 - val_loss: 1.4304 - val_accuracy: 0.5235\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 26s 20ms/step - loss: 1.0167 - accuracy: 0.6428 - val_loss: 1.3911 - val_accuracy: 0.5330\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 1.0046 - accuracy: 0.6457 - val_loss: 1.4094 - val_accuracy: 0.5354\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.0026 - accuracy: 0.6481 - val_loss: 1.3895 - val_accuracy: 0.5340\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.9864 - accuracy: 0.6517 - val_loss: 1.4077 - val_accuracy: 0.5276\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.9744 - accuracy: 0.6568 - val_loss: 1.3879 - val_accuracy: 0.5327\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.9700 - accuracy: 0.6569 - val_loss: 1.3920 - val_accuracy: 0.5354\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.9615 - accuracy: 0.6597 - val_loss: 1.4312 - val_accuracy: 0.5308\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9512 - accuracy: 0.6635 - val_loss: 1.4274 - val_accuracy: 0.5298\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 24s 20ms/step - loss: 0.9369 - accuracy: 0.6706 - val_loss: 1.4150 - val_accuracy: 0.5334\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.9329 - accuracy: 0.6715 - val_loss: 1.4065 - val_accuracy: 0.5414\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.9300 - accuracy: 0.6726 - val_loss: 1.4669 - val_accuracy: 0.5263\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), \n",
    "    callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 1.4547 - accuracy: 0.5254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4547209739685059, 0.5253999829292297]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Norm and Convolutions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(keras.layers.MaxPool2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer='he_normal'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('elu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               25700     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 251,218\n",
      "Trainable params: 246,706\n",
      "Non-trainable params: 4,512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same learning rate with conv layers?\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('models/ch11_model_batchnorm_conv.h5', save_best_only=True)\n",
    "run_logdir = os.path.join(os.curdir, 'cifar10_logs_batchnorm_conv', 'run_{:03d}'.format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 43s 28ms/step - loss: 1.7685 - accuracy: 0.3529 - val_loss: 1.7412 - val_accuracy: 0.3642\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 1.4785 - accuracy: 0.4668 - val_loss: 1.4275 - val_accuracy: 0.4948\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 34s 27ms/step - loss: 1.3685 - accuracy: 0.5109 - val_loss: 1.7144 - val_accuracy: 0.4442\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 1.2860 - accuracy: 0.5414 - val_loss: 1.3042 - val_accuracy: 0.5419\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 1.2132 - accuracy: 0.5699 - val_loss: 1.1431 - val_accuracy: 0.5977\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 34s 28ms/step - loss: 1.1508 - accuracy: 0.5929 - val_loss: 1.6163 - val_accuracy: 0.4944\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 1.1079 - accuracy: 0.6090 - val_loss: 1.3534 - val_accuracy: 0.5230\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 36s 29ms/step - loss: 1.0742 - accuracy: 0.6217 - val_loss: 1.1419 - val_accuracy: 0.5989\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 1.0319 - accuracy: 0.6418 - val_loss: 1.1489 - val_accuracy: 0.6078\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 36s 28ms/step - loss: 0.9990 - accuracy: 0.6493 - val_loss: 1.0712 - val_accuracy: 0.6268\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 0.9656 - accuracy: 0.6633 - val_loss: 1.1040 - val_accuracy: 0.6139\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 0.9315 - accuracy: 0.6748 - val_loss: 1.1222 - val_accuracy: 0.6193\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 0.9128 - accuracy: 0.6836 - val_loss: 1.0353 - val_accuracy: 0.6498\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 36s 29ms/step - loss: 0.8901 - accuracy: 0.6913 - val_loss: 1.0161 - val_accuracy: 0.6481\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 36s 29ms/step - loss: 0.8667 - accuracy: 0.6999 - val_loss: 1.0836 - val_accuracy: 0.6342\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 0.8443 - accuracy: 0.7064 - val_loss: 1.0171 - val_accuracy: 0.6552\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 0.8172 - accuracy: 0.7179 - val_loss: 1.0021 - val_accuracy: 0.6602\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 34s 27ms/step - loss: 0.8023 - accuracy: 0.7241 - val_loss: 1.0656 - val_accuracy: 0.6484\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 33s 26ms/step - loss: 0.7846 - accuracy: 0.7279 - val_loss: 0.9989 - val_accuracy: 0.6734\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 33s 27ms/step - loss: 0.7653 - accuracy: 0.7332 - val_loss: 1.1168 - val_accuracy: 0.6216\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 34s 27ms/step - loss: 0.7446 - accuracy: 0.7400 - val_loss: 0.9794 - val_accuracy: 0.6575\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 0.7250 - accuracy: 0.7495 - val_loss: 1.0293 - val_accuracy: 0.6608\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 33s 27ms/step - loss: 0.7091 - accuracy: 0.7536 - val_loss: 1.0795 - val_accuracy: 0.6574\n",
      "Epoch 24/100\n",
      " 590/1250 [=============>................] - ETA: 18s - loss: 0.6891 - accuracy: 0.7638"
     ]
    }
   ],
   "source": [
    "conv_hisotry = model.fit(\n",
    "    X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n",
    "    callbacks=[early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dropout to model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4daf73df99b5d5ee04b9c4f6d0c928016b99f4a7167499c60f06ba788794ec50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
